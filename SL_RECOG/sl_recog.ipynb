{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "path = r\"D:\\SignLanguage\\SL_RECOG\\300_DS\"\n",
    "files = os.listdir(path)\n",
    "files.sort()\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:38<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "image_array = []\n",
    "label_array = []\n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "    # liist of image in each folder\n",
    "    sub_file = os.listdir(path+\"/\"+files[i])\n",
    "    # print(len(sub_file))\n",
    "    \n",
    "    # loop through each sub_folder\n",
    "    for j in range (len(sub_file)):\n",
    "        # path of each image\n",
    "        file_path = path+\"/\"+files[i]+\"/\"+sub_file[j]\n",
    "\n",
    "        #read each image \n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        # resize image by 96x96\n",
    "        image = cv2.resize(image,(96,96))\n",
    "\n",
    "        #convert BGR image to RGB image \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # add this image to image_array\n",
    "        image_array.append(image)\n",
    "\n",
    "        # add labels to label_array\n",
    "        # i is number from 0 to len(files)-1\n",
    "        label_array.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to array \n",
    "np_image_array = np.array(image_array)\n",
    "np_label_array = np.array(label_array, dtype=\"float\")\n",
    "\n",
    "del image_array, label_array\n",
    "\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into test and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# X_train 85% X_test 15%\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(np_image_array,np_label_array, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,281\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,050,852</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,050,852\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,008,829</span> (15.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,008,829\u001b[0m (15.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,023</span> (164.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m42,023\u001b[0m (164.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from keras import layers, callbacks, utils, applications, optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "model = Sequential()\n",
    "pretranied_model = tf.keras.applications.EfficientNetB0(input_shape=(96,96,3), include_top=False)\n",
    "model.add(pretranied_model)\n",
    "\n",
    "# add pooling to model\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "# add dropout to model, increase accuracy reduce overfitting\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# add dense layer as an output \n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "# to see model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 676ms/step - loss: 5.3610 - mae: 5.3610 - val_loss: 5.7714 - val_mae: 5.7714 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 717ms/step - loss: 1.6674 - mae: 1.6674 - val_loss: 1.0719 - val_mae: 1.0719 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 653ms/step - loss: 1.0854 - mae: 1.0854 - val_loss: 1.5889 - val_mae: 1.5889 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 642ms/step - loss: 0.8963 - mae: 0.8963 - val_loss: 0.9892 - val_mae: 0.9892 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 583ms/step - loss: 0.9051 - mae: 0.9051 - val_loss: 1.2193 - val_mae: 1.2193 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 579ms/step - loss: 0.7537 - mae: 0.7537 - val_loss: 1.9925 - val_mae: 1.9925 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 595ms/step - loss: 0.7765 - mae: 0.7765 - val_loss: 0.6944 - val_mae: 0.6944 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 569ms/step - loss: 0.6775 - mae: 0.6775 - val_loss: 0.5730 - val_mae: 0.5730 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 600ms/step - loss: 0.6225 - mae: 0.6225 - val_loss: 0.5367 - val_mae: 0.5367 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 645ms/step - loss: 0.5668 - mae: 0.5668 - val_loss: 0.7407 - val_mae: 0.7407 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 673ms/step - loss: 0.5427 - mae: 0.5427 - val_loss: 0.4405 - val_mae: 0.4405 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 588ms/step - loss: 0.5496 - mae: 0.5496 - val_loss: 0.5048 - val_mae: 0.5048 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 550ms/step - loss: 0.5011 - mae: 0.5011 - val_loss: 0.6255 - val_mae: 0.6255 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 566ms/step - loss: 0.5429 - mae: 0.5429 - val_loss: 0.2608 - val_mae: 0.2608 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 554ms/step - loss: 0.5134 - mae: 0.5134 - val_loss: 0.8291 - val_mae: 0.8291 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 551ms/step - loss: 0.4913 - mae: 0.4913 - val_loss: 0.6123 - val_mae: 0.6123 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 556ms/step - loss: 0.4495 - mae: 0.4495 - val_loss: 1.0370 - val_mae: 1.0370 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 566ms/step - loss: 0.4562 - mae: 0.4562 - val_loss: 0.6013 - val_mae: 0.6013 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step - loss: 0.4678 - mae: 0.4678\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 568ms/step - loss: 0.4678 - mae: 0.4678 - val_loss: 0.3861 - val_mae: 0.3861 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 574ms/step - loss: 0.4467 - mae: 0.4467 - val_loss: 0.2824 - val_mae: 0.2824 - learning_rate: 9.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 644ms/step - loss: 0.4440 - mae: 0.4440 - val_loss: 0.4893 - val_mae: 0.4893 - learning_rate: 9.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 643ms/step - loss: 0.8652 - mae: 0.8652 - val_loss: 0.6684 - val_mae: 0.6684 - learning_rate: 9.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 637ms/step - loss: 0.5262 - mae: 0.5262 - val_loss: 0.8844 - val_mae: 0.8844 - learning_rate: 9.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - loss: 0.4344 - mae: 0.4344\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 684ms/step - loss: 0.4344 - mae: 0.4344 - val_loss: 0.3049 - val_mae: 0.3049 - learning_rate: 9.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 684ms/step - loss: 0.4081 - mae: 0.4081 - val_loss: 0.8682 - val_mae: 0.8682 - learning_rate: 8.1000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 686ms/step - loss: 0.4454 - mae: 0.4454 - val_loss: 0.6400 - val_mae: 0.6400 - learning_rate: 8.1000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 600ms/step - loss: 0.4700 - mae: 0.4700 - val_loss: 0.3189 - val_mae: 0.3189 - learning_rate: 8.1000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 606ms/step - loss: 0.4188 - mae: 0.4188 - val_loss: 0.2364 - val_mae: 0.2364 - learning_rate: 8.1000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 593ms/step - loss: 0.3894 - mae: 0.3894 - val_loss: 0.3004 - val_mae: 0.3004 - learning_rate: 8.1000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 591ms/step - loss: 0.4192 - mae: 0.4192 - val_loss: 0.3152 - val_mae: 0.3152 - learning_rate: 8.1000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 594ms/step - loss: 0.4405 - mae: 0.4405 - val_loss: 0.4706 - val_mae: 0.4706 - learning_rate: 8.1000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 584ms/step - loss: 0.3922 - mae: 0.3922 - val_loss: 0.9191 - val_mae: 0.9191 - learning_rate: 8.1000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - loss: 0.3824 - mae: 0.3824\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 574ms/step - loss: 0.3824 - mae: 0.3824 - val_loss: 0.8084 - val_mae: 0.8084 - learning_rate: 8.1000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 587ms/step - loss: 0.3871 - mae: 0.3871 - val_loss: 0.3038 - val_mae: 0.3038 - learning_rate: 7.2900e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 597ms/step - loss: 0.3832 - mae: 0.3832 - val_loss: 0.2594 - val_mae: 0.2594 - learning_rate: 7.2900e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 593ms/step - loss: 0.3855 - mae: 0.3855 - val_loss: 0.2833 - val_mae: 0.2833 - learning_rate: 7.2900e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 595ms/step - loss: 0.3929 - mae: 0.3929 - val_loss: 1.3624 - val_mae: 1.3624 - learning_rate: 7.2900e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576ms/step - loss: 0.4849 - mae: 0.4849\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 594ms/step - loss: 0.4847 - mae: 0.4847 - val_loss: 0.6306 - val_mae: 0.6306 - learning_rate: 7.2900e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 616ms/step - loss: 0.4054 - mae: 0.4054 - val_loss: 0.1788 - val_mae: 0.1788 - learning_rate: 6.5610e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 593ms/step - loss: 0.3997 - mae: 0.3997 - val_loss: 0.2872 - val_mae: 0.2872 - learning_rate: 6.5610e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 594ms/step - loss: 0.5225 - mae: 0.5225 - val_loss: 0.2619 - val_mae: 0.2619 - learning_rate: 6.5610e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 603ms/step - loss: 0.3582 - mae: 0.3582 - val_loss: 0.2172 - val_mae: 0.2172 - learning_rate: 6.5610e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 604ms/step - loss: 0.3575 - mae: 0.3575 - val_loss: 0.4484 - val_mae: 0.4484 - learning_rate: 6.5610e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - loss: 0.3657 - mae: 0.3657\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 595ms/step - loss: 0.3657 - mae: 0.3657 - val_loss: 0.3468 - val_mae: 0.3468 - learning_rate: 6.5610e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 596ms/step - loss: 0.3566 - mae: 0.3566 - val_loss: 0.4454 - val_mae: 0.4454 - learning_rate: 5.9049e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 582ms/step - loss: 0.3485 - mae: 0.3485 - val_loss: 0.3483 - val_mae: 0.3483 - learning_rate: 5.9049e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 609ms/step - loss: 0.3428 - mae: 0.3428 - val_loss: 0.1609 - val_mae: 0.1609 - learning_rate: 5.9049e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 614ms/step - loss: 0.3330 - mae: 0.3330 - val_loss: 0.4485 - val_mae: 0.4485 - learning_rate: 5.9049e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 606ms/step - loss: 0.3421 - mae: 0.3421 - val_loss: 0.1571 - val_mae: 0.1571 - learning_rate: 5.9049e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 583ms/step - loss: 0.3384 - mae: 0.3384 - val_loss: 0.2255 - val_mae: 0.2255 - learning_rate: 5.9049e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 609ms/step - loss: 0.3330 - mae: 0.3330 - val_loss: 0.3107 - val_mae: 0.3107 - learning_rate: 5.9049e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 624ms/step - loss: 0.3224 - mae: 0.3224 - val_loss: 0.2910 - val_mae: 0.2910 - learning_rate: 5.9049e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 608ms/step - loss: 0.3381 - mae: 0.3381 - val_loss: 0.1350 - val_mae: 0.1350 - learning_rate: 5.9049e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 597ms/step - loss: 0.3528 - mae: 0.3528 - val_loss: 0.1542 - val_mae: 0.1542 - learning_rate: 5.9049e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 598ms/step - loss: 0.3321 - mae: 0.3321 - val_loss: 0.2606 - val_mae: 0.2606 - learning_rate: 5.9049e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 597ms/step - loss: 0.3361 - mae: 0.3361 - val_loss: 0.2877 - val_mae: 0.2877 - learning_rate: 5.9049e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 600ms/step - loss: 0.3368 - mae: 0.3368 - val_loss: 0.3757 - val_mae: 0.3757 - learning_rate: 5.9049e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 610ms/step - loss: 0.3363 - mae: 0.3363 - val_loss: 0.1243 - val_mae: 0.1243 - learning_rate: 5.9049e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 598ms/step - loss: 0.3604 - mae: 0.3604 - val_loss: 0.4865 - val_mae: 0.4865 - learning_rate: 5.9049e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 593ms/step - loss: 0.3522 - mae: 0.3522 - val_loss: 0.2207 - val_mae: 0.2207 - learning_rate: 5.9049e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 610ms/step - loss: 0.3485 - mae: 0.3485 - val_loss: 0.1213 - val_mae: 0.1213 - learning_rate: 5.9049e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 662ms/step - loss: 0.3294 - mae: 0.3294 - val_loss: 0.2632 - val_mae: 0.2632 - learning_rate: 5.9049e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 621ms/step - loss: 0.3455 - mae: 0.3455 - val_loss: 0.1566 - val_mae: 0.1566 - learning_rate: 5.9049e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 622ms/step - loss: 0.3341 - mae: 0.3341 - val_loss: 0.1168 - val_mae: 0.1168 - learning_rate: 5.9049e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 616ms/step - loss: 0.3364 - mae: 0.3364 - val_loss: 0.2752 - val_mae: 0.2752 - learning_rate: 5.9049e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 635ms/step - loss: 0.3355 - mae: 0.3355 - val_loss: 0.3451 - val_mae: 0.3451 - learning_rate: 5.9049e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 584ms/step - loss: 0.3284 - mae: 0.3284 - val_loss: 0.1060 - val_mae: 0.1060 - learning_rate: 5.9049e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 568ms/step - loss: 0.3236 - mae: 0.3236 - val_loss: 0.1732 - val_mae: 0.1732 - learning_rate: 5.9049e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 564ms/step - loss: 0.3312 - mae: 0.3312 - val_loss: 0.1061 - val_mae: 0.1061 - learning_rate: 5.9049e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 566ms/step - loss: 0.3268 - mae: 0.3268 - val_loss: 0.2994 - val_mae: 0.2994 - learning_rate: 5.9049e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 568ms/step - loss: 0.3151 - mae: 0.3151 - val_loss: 0.2311 - val_mae: 0.2311 - learning_rate: 5.9049e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - loss: 0.3324 - mae: 0.3324\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 602ms/step - loss: 0.3324 - mae: 0.3324 - val_loss: 0.1981 - val_mae: 0.1981 - learning_rate: 5.9049e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 568ms/step - loss: 0.3344 - mae: 0.3344 - val_loss: 0.1130 - val_mae: 0.1130 - learning_rate: 5.3144e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 575ms/step - loss: 0.3234 - mae: 0.3234 - val_loss: 0.1952 - val_mae: 0.1952 - learning_rate: 5.3144e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 667ms/step - loss: 0.3075 - mae: 0.3075 - val_loss: 0.3302 - val_mae: 0.3302 - learning_rate: 5.3144e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 666ms/step - loss: 0.3104 - mae: 0.3104 - val_loss: 0.1473 - val_mae: 0.1473 - learning_rate: 5.3144e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616ms/step - loss: 0.3166 - mae: 0.3166\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 635ms/step - loss: 0.3166 - mae: 0.3166 - val_loss: 0.1600 - val_mae: 0.1600 - learning_rate: 5.3144e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 637ms/step - loss: 0.3129 - mae: 0.3129 - val_loss: 0.3926 - val_mae: 0.3926 - learning_rate: 4.7830e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 593ms/step - loss: 0.3035 - mae: 0.3035 - val_loss: 0.1989 - val_mae: 0.1989 - learning_rate: 4.7830e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 627ms/step - loss: 0.3178 - mae: 0.3178 - val_loss: 0.0817 - val_mae: 0.0817 - learning_rate: 4.7830e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 589ms/step - loss: 0.3046 - mae: 0.3046 - val_loss: 0.0977 - val_mae: 0.0977 - learning_rate: 4.7830e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 642ms/step - loss: 0.3132 - mae: 0.3132 - val_loss: 0.1357 - val_mae: 0.1357 - learning_rate: 4.7830e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 623ms/step - loss: 0.3064 - mae: 0.3064 - val_loss: 0.3226 - val_mae: 0.3226 - learning_rate: 4.7830e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 574ms/step - loss: 0.3017 - mae: 0.3017 - val_loss: 0.0950 - val_mae: 0.0950 - learning_rate: 4.7830e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step - loss: 0.3047 - mae: 0.3047\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 568ms/step - loss: 0.3047 - mae: 0.3047 - val_loss: 0.2785 - val_mae: 0.2785 - learning_rate: 4.7830e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 554ms/step - loss: 0.3011 - mae: 0.3011 - val_loss: 0.2278 - val_mae: 0.2278 - learning_rate: 4.3047e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 557ms/step - loss: 0.3055 - mae: 0.3055 - val_loss: 0.0884 - val_mae: 0.0884 - learning_rate: 4.3047e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 573ms/step - loss: 0.3004 - mae: 0.3004 - val_loss: 0.1717 - val_mae: 0.1717 - learning_rate: 4.3047e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 687ms/step - loss: 0.3143 - mae: 0.3143 - val_loss: 0.2440 - val_mae: 0.2440 - learning_rate: 4.3047e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - loss: 0.3218 - mae: 0.3218\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 618ms/step - loss: 0.3218 - mae: 0.3218 - val_loss: 0.1066 - val_mae: 0.1066 - learning_rate: 4.3047e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 572ms/step - loss: 0.2951 - mae: 0.2951 - val_loss: 0.1094 - val_mae: 0.1094 - learning_rate: 3.8742e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 560ms/step - loss: 0.3035 - mae: 0.3035 - val_loss: 0.1673 - val_mae: 0.1673 - learning_rate: 3.8742e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 548ms/step - loss: 0.3057 - mae: 0.3057 - val_loss: 0.1712 - val_mae: 0.1712 - learning_rate: 3.8742e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 547ms/step - loss: 0.2941 - mae: 0.2941 - val_loss: 0.0888 - val_mae: 0.0888 - learning_rate: 3.8742e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step - loss: 0.2987 - mae: 0.2987\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 571ms/step - loss: 0.2987 - mae: 0.2987 - val_loss: 0.2189 - val_mae: 0.2189 - learning_rate: 3.8742e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 564ms/step - loss: 0.3004 - mae: 0.3004 - val_loss: 0.2580 - val_mae: 0.2580 - learning_rate: 3.4868e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 545ms/step - loss: 0.2939 - mae: 0.2939 - val_loss: 0.2786 - val_mae: 0.2786 - learning_rate: 3.4868e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 588ms/step - loss: 0.2938 - mae: 0.2938 - val_loss: 0.0822 - val_mae: 0.0822 - learning_rate: 3.4868e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 561ms/step - loss: 0.2949 - mae: 0.2949 - val_loss: 0.1119 - val_mae: 0.1119 - learning_rate: 3.4868e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 568ms/step - loss: 0.2836 - mae: 0.2836 - val_loss: 0.0577 - val_mae: 0.0577 - learning_rate: 3.4868e-04\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"mae\"])\n",
    "\n",
    "# Create Checkpoint\n",
    "ckp_path = r\"D:\\SignLanguage\\SL_RECOG\\trained_model\\model.weights.h5\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=ckp_path,\n",
    "    monitor=\"val_mae\",\n",
    "    mode=\"auto\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "# monitor: monitor validation mae loss to save model \n",
    "# mode: use to save mode when val_mae is minimum or max\n",
    "# it has 3 options: min, max, auto \n",
    "# when val_mae reduce model will be saved \n",
    "# save bst only: flase -> save all model \n",
    "# save wgths only: save only weight\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    factor=0.9,\n",
    "    monitor=\"val_mae\",\n",
    "    mode=\"auto\",\n",
    "    cooldown=0,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# factor: when it is reduce nxt lr will be .9 * current lr \n",
    "# patience = x \n",
    "# reduce lr after X epoch whenn accrucay does not imporve \n",
    "# verbose: show it after every epoch\n",
    "\n",
    "# Start Training \n",
    "Epochs = 100\n",
    "Batch_Size = 32 \n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    validation_data=(X_test,Y_test),\n",
    "    batch_size=Batch_Size,\n",
    "    epochs=Epochs,\n",
    "    callbacks=[model_checkpoint, reduce_lr]\n",
    ")      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
